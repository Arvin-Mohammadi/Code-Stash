{"cells":[{"cell_type":"markdown","metadata":{"id":"gDybUz11uJrM"},"source":["# DQN using Pytorch\n","\n","Basically copied from the dqn_tutorial-pytorch but adapted for our environment"]},{"cell_type":"code","source":["!pip install gym[box2d]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qQjOuT0uXEN","executionInfo":{"status":"ok","timestamp":1705583975655,"user_tz":-210,"elapsed":3746,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}},"outputId":"16d8d933-f0dc-483a-a4d2-eeec0d3326a6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n","Collecting box2d-py==2.3.5 (from gym[box2d])\n","  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pygame==2.1.0 (from gym[box2d])\n","  Using cached pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","Collecting swig==4.* (from gym[box2d])\n","  Using cached swig-4.1.1.post1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n","Building wheels for collected packages: box2d-py\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n","Failed to build box2d-py\n","\u001b[31mERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0ZFI6yJ9uJrO","executionInfo":{"status":"ok","timestamp":1705583951915,"user_tz":-210,"elapsed":411,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["import numpy as np\n","import gym\n","from IPython.display import clear_output, display\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import random\n","import copy\n","import time\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"szSQ1DauuJrP","executionInfo":{"status":"error","timestamp":1705583952263,"user_tz":-210,"elapsed":13,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}},"outputId":"c27845fd-3af1-411a-ab21-96bdb14bbcef"},"outputs":[{"output_type":"error","ename":"DependencyNotInstalled","evalue":"box2D is not installed, run `pip install gym[box2d]`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/box2d/bipedal_walker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mBox2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     from Box2D.b2 import (\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-7d11afb6d063>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLander-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/box2d/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbipedal_walker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBipedalWalker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBipedalWalkerHardcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcar_racing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarRacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlunar_lander\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLunarLander\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLunarLanderContinuous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/box2d/bipedal_walker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mDependencyNotInstalled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"box2D is not installed, run `pip install gym[box2d]`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDependencyNotInstalled\u001b[0m: box2D is not installed, run `pip install gym[box2d]`"]}],"source":["env = gym.make('LunarLander-v2')"]},{"cell_type":"markdown","metadata":{"id":"o9OedAk8uJrQ"},"source":["## Creating the Deep Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxxNhzW-uJrQ","executionInfo":{"status":"aborted","timestamp":1705583952264,"user_tz":-210,"elapsed":7,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["class Network(nn.Module):\n","\n","    def __init__(self, state_num , action_num, hidden_layer):\n","\n","        super(Network, self).__init__()\n","        self.input_layer = nn.Linear(state_num, hidden_layer)\n","        self.h1_layer = nn.Linear(hidden_layer, hidden_layer)\n","        self.h2_layer = nn.Linear(hidden_layer, hidden_layer)\n","        self.output_layer = nn.Linear(hidden_layer, action_num)\n","\n","\n","    def forward(self, state):\n","\n","        xh = F.relu(self.input_layer(state))\n","        hh1 = F.relu(self.h1_layer(xh))\n","        hh2 = F.tanh(self.h2_layer(hh1))\n","        state_action_values = self.output_layer(hh2)\n","\n","        return state_action_values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUNopl6YuJrR","executionInfo":{"status":"aborted","timestamp":1705583952264,"user_tz":-210,"elapsed":6,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["class Q_Network(nn.Module):\n","    def __init__(self, state_dim , action_dim):\n","        super(Q_Network, self).__init__()\n","        self.x_layer = nn.Linear(state_dim, 150)\n","        self.h_layer = nn.Linear(150, 120)\n","        self.y_layer = nn.Linear(120, action_dim)\n","        print(self.x_layer)\n","\n","    def forward(self, state):\n","        xh = F.relu(self.x_layer(state))\n","        hh = F.relu(self.h_layer(xh))\n","        state_action_values = self.y_layer(hh)\n","        return state_action_values"]},{"cell_type":"markdown","metadata":{"id":"0USUmAsMuJrR"},"source":["## Making the Agent"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"GBKMmyM1uJrR","executionInfo":{"status":"ok","timestamp":1705583953478,"user_tz":-210,"elapsed":3,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["class DQNAgent(object):\n","    def __init__(self, state_dim, action_dim):\n","        self.qnet = Q_Network(state_dim, action_dim)\n","        self.qnet_optim = torch.optim.Adam(self.qnet.parameters(), lr=0.001)\n","        self.discount_factor = 0.99\n","        self.MSELoss_function = nn.MSELoss()\n","        self.replay_buffer = ReplayBuffer()\n","        pass\n","\n","    def epsilon_greedy_action(self, state, epsilon):\n","        if np.random.uniform(0, 1) < epsilon:\n","                return env.action_space.sample()  # choose random action\n","        else:\n","                network_output_to_numpy = self.qnet(state).data.numpy()\n","                return np.argmax(network_output_to_numpy)  # choose greedy action\n","\n","    def update_Q_Network(self, state, next_state, action, reward, terminals):\n","\n","        qsa = torch.gather(self.qnet(state), dim=1, index=action.long())\n","        qsa_next_action = self.qnet(next_state)\n","        qsa_next_action,_ = torch.max(qsa_next_action, dim=1, keepdim=True)\n","        not_terminals = 1 - terminals\n","        qsa_next_target = reward + not_terminals * self.discount_factor * qsa_next_action\n","        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n","        self.qnet_optim.zero_grad()\n","        q_network_loss.backward()\n","        self.qnet_optim.step()\n","\n","\n","    def update_Sarsa_Network(self, state, next_state, action, next_action, reward, terminals):\n","\n","        qsa = torch.gather(self.qnet(state), dim=1, index=action.long())\n","\n","        qsa_next_action = torch.gather(self.qnet(next_state), dim=1, index=next_action.long())\n","\n","        not_terminals = 1 - terminals\n","\n","        qsa_next_target = reward + not_terminals * (self.discount_factor * qsa_next_action)\n","\n","        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n","        self.qnet_optim.zero_grad()\n","        q_network_loss.backward()\n","        self.qnet_optim.step()\n","\n","    def update(self, update_rate):\n","        for i in range(update_rate):\n","            states, next_states, actions, rewards, terminals = self.replay_buffer.sample_minibatch(64)\n","            states = torch.Tensor(states)\n","            next_states = torch.Tensor(next_states)\n","            actions = torch.Tensor(actions)\n","            rewards = torch.Tensor(rewards)\n","            terminals = torch.Tensor(terminals)\n","            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n","\n","    def update_s(self, update_rate):\n","        for i in range(update_rate):\n","            states, next_states, actions, next_actions, rewards, terminals = self.replay_buffer.sample_minibatch_sarsa(64)\n","            states = torch.Tensor(states)\n","            next_states = torch.Tensor(next_states)\n","            actions = torch.Tensor(actions)\n","            next_actions = torch.Tensor(next_actions)\n","            rewards = torch.Tensor(rewards)\n","            terminals = torch.Tensor(terminals)\n","            self.update_Sarsa_Network(states, next_states, actions, next_actions, rewards, terminals)\n","\n","    def best_move(self, state):\n","\n","        return np.argmax(self.qnet(state).data.numpy())"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"M3vOx_1LuJrS","executionInfo":{"status":"ok","timestamp":1705583954578,"user_tz":-210,"elapsed":15,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["class ReplayBuffer(object):\n","    def __init__(self):\n","        self.buffer = []\n","        self.buffer_s = []\n","\n","    def add_to_buffer(self, data):\n","        #data must be of the form (state,next_state,action,reward,terminal)\n","        self.buffer.append(data)\n","\n","    def add_to_buffer_sarsa(self, data):\n","        #data must be of the form (state,next_state,action,n_action,reward,terminal)\n","        self.buffer_s.append(data)\n","\n","    def sample_minibatch(self,minibatch_length):\n","        states = []\n","        next_states = []\n","        actions = []\n","        rewards = []\n","        terminals = []\n","        for i in range(minibatch_length):\n","            random_int = np.random.randint(0, len(self.buffer)-1)\n","            transition = self.buffer[random_int]\n","            states.append(transition[0])\n","            next_states.append(transition[1])\n","            actions.append(transition[2])\n","            rewards.append(transition[3])\n","            terminals.append(transition[4])\n","        return torch.Tensor(states), torch.Tensor(next_states), torch.Tensor(actions), torch.Tensor(rewards), torch.Tensor(terminals)\n","\n","    def sample_minibatch_sarsa(self,minibatch_length):\n","        states = []\n","        next_states = []\n","        actions = []\n","        next_actions = []\n","        rewards = []\n","        terminals = []\n","        for i in range(minibatch_length):\n","            random_int = np.random.randint(0, len(self.buffer_s)-1)\n","            transition = self.buffer_s[random_int]\n","            states.append(transition[0])\n","            next_states.append(transition[1])\n","            actions.append(transition[2])\n","            next_actions.append(transition[3])\n","            rewards.append(transition[4])\n","            terminals.append(transition[5])\n","        return torch.Tensor(states), torch.Tensor(next_states), torch.Tensor(actions), torch.Tensor(next_actions), torch.Tensor(rewards), torch.Tensor(terminals)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":199},"id":"QLfV0_WLuJrS","executionInfo":{"status":"error","timestamp":1705583954579,"user_tz":-210,"elapsed":15,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}},"outputId":"af7d609b-f450-4ff2-8cf0-80760283153c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'env' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-84d7f5584abe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maction_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstate_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"]}],"source":["action_dim = env.action_space.n\n","state_dim = env.observation_space.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"mqE6LbkVuJrT"},"source":["# Deep Sarsa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cVpSVpqEuJrT","executionInfo":{"status":"aborted","timestamp":1705583954579,"user_tz":-210,"elapsed":12,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["agent = DQNAgent(state_dim, action_dim)\n","number_of_episodes = 600\n","max_time_steps = 2000\n","epsilon = 1\n","reward_list_sarsa = []\n","final_rewards = []\n","\n","np.random.seed(0)\n","for episode in range(number_of_episodes):\n","    state = env.reset()\n","\n","    reward_sum = 0\n","\n","    action = agent.epsilon_greedy_action(state, epsilon)\n","\n","    state_1, reward, terminal, _, _ = env.step(action)\n","\n","    #Checks for early Finish\n","    if terminal:\n","\n","        action_1 = agent.epsilon_greedy_action(state_1, epsilon)\n","        agent.replay_buffer.add_to_buffer_sarsa((state, state_1, [action], [action_1], [reward],[terminal]))\n","\n","        reward_sum += reward\n","\n","        final_rewards.append(reward)\n","\n","        reward_list_sarsa.append(reward_sum)\n","\n","        clear_output(wait=True)\n","        print('Early finish!', 'reward =', reward)\n","        print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum, 'final reward', \\\n","                      reward, 'epsilon:', epsilon)\n","\n","    #If not finished after first action - continue learning\n","    else:\n","        for i in range(max_time_steps):\n","\n","            action_1 = agent.epsilon_greedy_action(state_1, epsilon)\n","\n","            state_2, reward_1, terminal_1, _, _ = env.step(action_1)\n","\n","            agent.replay_buffer.add_to_buffer_sarsa((state, state_1, [action], [action_1], [reward],[terminal]))\n","\n","            reward_sum += reward\n","\n","            state = state_1\n","            state_1 = state_2\n","            action = action_1\n","            reward = reward_1\n","            terminal = terminal_1\n","\n","            if terminal:\n","\n","                action_1 = agent.epsilon_greedy_action(state_1, epsilon)\n","\n","                agent.replay_buffer.add_to_buffer_sarsa((state, state_1, [action], [action_1], [reward],[terminal]))\n","\n","                reward_sum += reward\n","\n","                final_rewards.append(reward)\n","\n","                reward_list_sarsa.append(reward_sum)\n","\n","                clear_output(wait=True)\n","                print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum, 'final reward', \\\n","                      reward, 'epsilon:', epsilon)\n","\n","\n","                break\n","\n","    agent.update_s(128)\n","\n","    if epsilon > 0.2:\n","        epsilon *= 0.995\n","\n","    if epsilon <= 0.2:\n","        epsilon = 0.2\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tNez_EguJrU","executionInfo":{"status":"aborted","timestamp":1705583954579,"user_tz":-210,"elapsed":12,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["def m_a(values, window=50):\n","    weight = np.repeat(1.0, window)/window\n","    smas = np.convolve(values,weight,'valid')\n","    return smas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnPcy59wuJrU","executionInfo":{"status":"aborted","timestamp":1705583954580,"user_tz":-210,"elapsed":13,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["smas = m_a(reward_list_sarsa)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqoGHgvOuJrU","executionInfo":{"status":"aborted","timestamp":1705583954580,"user_tz":-210,"elapsed":13,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["# np.where(smas >100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JL-MvE_uJrU","executionInfo":{"status":"aborted","timestamp":1705583954580,"user_tz":-210,"elapsed":12,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10,5))\n","\n","ax.plot(reward_list_sarsa)\n","ax.plot(smas)\n","ax.set_ylabel('Rewards')\n","ax.set_xlabel('Episodes')\n","ax.set_title('Deep SARSA learning (600 episodes training)')\n","#plt.savefig('Sarsa600epma', transparent=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWufXHeUuJrV","executionInfo":{"status":"aborted","timestamp":1705583954580,"user_tz":-210,"elapsed":10,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["# import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCsv9gniuJrV","executionInfo":{"status":"aborted","timestamp":1705583954580,"user_tz":-210,"elapsed":10,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["# ep_600 = reward_list_sarsa\n","# with open(\"rewards_ep.txt\", \"wb\") as fp:\n","#     pickle.dump(ep_600, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5whUdOYuJrV","executionInfo":{"status":"aborted","timestamp":1705583954581,"user_tz":-210,"elapsed":11,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["# with open(\"rewards_ep.txt\", \"rb\") as fp:\n","#     imported = pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w45sKT4yuJrV","executionInfo":{"status":"aborted","timestamp":1705583954581,"user_tz":-210,"elapsed":11,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["# smass = m_a(imported)"]},{"cell_type":"markdown","metadata":{"id":"LUIgIIOJuJrV"},"source":["\n","# Deep Q Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"WlZ-imIMuJrV","executionInfo":{"status":"aborted","timestamp":1705583954581,"user_tz":-210,"elapsed":10,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["agent = DQNAgent(state_dim, action_dim)\n","number_of_episodes = 600\n","max_time_steps = 2000\n","reward_list = []\n","epsilon = 1\n","finals = []\n","\n","\n","for episode in range(number_of_episodes):\n","    reward_sum = 0\n","    state = env.reset()\n","\n","    for _ in range(max_time_steps):\n","        action = agent.epsilon_greedy_action(torch.from_numpy(state).float() , epsilon)\n","        next_state, reward, terminal, _ = env.step(action)\n","\n","        reward_sum += reward\n","        agent.replay_buffer.add_to_buffer((state,next_state,[action],[reward],[terminal]))\n","        state = next_state\n","        if terminal:\n","            clear_output(wait=True)\n","            print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum)\n","            reward_list.append(reward_sum)\n","            finals.append(reward)\n","            break\n","\n","    agent.update(128)\n","\n","    if epsilon > 0.2:\n","        epsilon *= 0.995 #Epsilon decay\n","\n","    if epsilon <= 0.2:\n","        epsilon = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDSsrcLWuJrV","executionInfo":{"status":"aborted","timestamp":1705583954581,"user_tz":-210,"elapsed":10,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["smas_ = m_a(reward_list)\n","# np.where(smas_> 100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BkpvXN8uJrV","executionInfo":{"status":"aborted","timestamp":1705583954581,"user_tz":-210,"elapsed":9,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10,5))\n","\n","ax.plot(reward_list)\n","ax.plot(smas_)\n","ax.set_ylabel('Rewards')\n","ax.set_xlabel('Episodes')\n","ax.set_title('Deep Q learning (600 episodes training)')\n","plt.savefig('DQN600epma', transparent=True)"]},{"cell_type":"markdown","metadata":{"id":"nLhTRLVQuJrW"},"source":["# Visualise the Model"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TOf3gXsuuJrW","executionInfo":{"status":"ok","timestamp":1705583955084,"user_tz":-210,"elapsed":4,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"outputs":[],"source":["# state = env.reset()\n","\n","# while True:\n","\n","#     env.render()\n","#     action = agent.best_move(torch.from_numpy(state).float())\n","\n","#     next_state, _, terminal, _ = env.step(action)\n","\n","#     state = next_state\n","\n","#     if terminal:\n","#         break\n","\n","# env.close()"]},{"cell_type":"code","source":[],"metadata":{"id":"g1AlyscWuOxQ","executionInfo":{"status":"ok","timestamp":1705583955446,"user_tz":-210,"elapsed":3,"user":{"displayName":"Arvin Mohammadi","userId":"14054999000878298543"}}},"execution_count":9,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"ai","language":"python","name":"ai"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}